{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(1, \"..\")\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from main_code.utils.data.data_sets import DiskTSPTestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_coords(tsp_instance, num_nodes):\n",
    "    derivate = tsp_instance.split(' ')\n",
    "    x = np.array(derivate[0:2*num_nodes:2], dtype = np.float64).reshape((-1,1))\n",
    "    y = np.array(derivate[1:2*num_nodes:2], dtype = np.float64).reshape((-1,1))\n",
    "    coords = np.concatenate((x, y), axis=1)\n",
    "    return coords\n",
    "\n",
    "def extract_sol(tsp_instance, num_nodes):\n",
    "    derivate = tsp_instance.split(' ')\n",
    "    opt_sol = np.array(derivate[2*num_nodes+1:-1], dtype = np.int32) - 1 \n",
    "    return opt_sol[0:num_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data\n",
    "num_nodes = 1000\n",
    "f = open('../data/test_sets/fu_et_al/tsp{}_test_concorde.txt'.format(num_nodes), 'r')\n",
    "testset_tsp = f.readlines()\n",
    "f.close()\n",
    "num_samples = len(testset_tsp)\n",
    "# general save path\n",
    "test_set_name = f\"fu_et_al_n_{num_nodes}_{num_samples}\"\n",
    "save_path = f\"../data/test_sets/{test_set_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_length(node_feats, sol):\n",
    "    length = 0\n",
    "    for i in range(sol.shape[0] - 1):\n",
    "        first = sol[i]\n",
    "        sec = sol[i+1]\n",
    "        difference = node_feats[first] - node_feats[sec]\n",
    "        # print(difference)\n",
    "        summed_square = np.sum(np.square(difference))\n",
    "        # print(summed_square)\n",
    "        length += np.sqrt(summed_square)\n",
    "    length += np.sqrt(np.sum(np.square(node_feats[sol[0]] - node_feats[sol[-1]])))\n",
    "    return length\n",
    "\n",
    "def calc_tour_length(node_feats, sol):\n",
    "    # calculate length of the tour\n",
    "    differences = node_feats[sol,:] - np.roll(node_feats[sol,:], shift=-1, axis=0)\n",
    "    summed_squares = np.sum(np.square(differences), axis=1)\n",
    "    length = np.sum(np.sqrt(summed_squares))\n",
    "    return length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tsp_data(save_path, idx, num_samples):\n",
    "    # save everything\n",
    "    idx_str = f'{idx}'.zfill(len(str(num_samples)))\n",
    "    problem_name = f'tsp_{idx_str}'\n",
    "    instance_path = f'{save_path}/{problem_name}'\n",
    "    if not os.path.exists(instance_path):\n",
    "        os.makedirs(instance_path)\n",
    "    node_feats = extract_node_coords(tsp_instance, num_nodes=num_nodes)\n",
    "    np.savetxt(f'{instance_path}/node_feats.txt', node_feats)\n",
    "    sol = extract_sol(tsp_instance, num_nodes)\n",
    "\n",
    "    length = calc_tour_length(node_feats, sol)\n",
    "\n",
    "    # save solution data to folder\n",
    "    solution_data = {\n",
    "        'problem_name': problem_name,\n",
    "        'opt_tour_length': length,\n",
    "        'opt_tour': sol.tolist()\n",
    "    }\n",
    "    with open(f\"{instance_path}/solution.json\", 'w') as f:\n",
    "        # indent=2 is not needed but makes the file human-readable\n",
    "        json.dump(solution_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, tsp_instance in enumerate(testset_tsp):\n",
    "    save_tsp_data(save_path, idx, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample small sub test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../data/test_sets/fu_et_al_n_100_10000\"\n",
    "dataset =  DiskTSPTestSet(dataset_path, use_pomo_aug=False, sampling_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(37)\n",
    "indices = random.sample(range(len(dataset)), 128)\n",
    "subset = torch.utils.data.Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 75, 54, 60, 51, 36, 53, 48,  5, 66, 73, 42, 47, 56, 82, 85, 81,\n",
       "       68, 92, 95, 35, 12, 96, 41, 62, 19, 58, 11, 88, 55, 26, 29, 71, 37,\n",
       "       23, 20, 97,  1, 25, 83, 50,  4, 33, 59, 80,  3, 24, 32, 63, 38, 46,\n",
       "       10, 34, 40, 43, 14, 17, 69, 21, 27, 79, 31, 78, 49, 57, 74, 16, 84,\n",
       "        2, 65, 39, 45, 44, 87, 94, 70, 86, 22, 64, 77, 89, 67,  7, 72, 99,\n",
       "       90, 18, 76,  8, 93, 52, 13, 91,  6, 61,  9, 28, 15, 98, 30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save subset into new folder\n",
    "def sample_and_save_subset(dataset, save_path, seed=37):\n",
    "    random.seed(37)\n",
    "    indices = random.sample(range(len(dataset)), 128)\n",
    "    subset = torch.utils.data.Subset(dataset, indices)\n",
    "    # save data in new folder\n",
    "    # make sure length stays the same\n",
    "    for idx, data in enumerate(subset):\n",
    "        idx_str = f'{idx}'.zfill(len(str(len(subset))))\n",
    "        problem_name = f'tsp_{idx_str}'\n",
    "        instance_path = f'{save_path}/{problem_name}'\n",
    "        if not os.path.exists(instance_path):\n",
    "            os.makedirs(instance_path) \n",
    "        node_feats = data[0]\n",
    "        np.savetxt(f'{instance_path}/node_feats.txt', node_feats)\n",
    "        sol = data[2]\n",
    "        length = calc_tour_length(node_feats, sol)\n",
    "        assert(data[1] == length)\n",
    "        # save solution data to folder\n",
    "        solution_data = {\n",
    "            'problem_name': problem_name,\n",
    "            'opt_tour_length': length,\n",
    "            'opt_tour': sol.tolist()\n",
    "        }\n",
    "        with open(f\"{instance_path}/solution.json\", 'w') as f:\n",
    "            # indent=2 is not needed but makes the file human-readable\n",
    "            json.dump(solution_data, f, indent=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_and_save_subset(dataset, save_path=\"../data/test_sets/fu_et_al_sample_n_100_128\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e6621387889b70cdd8f73a623ec71bd71fd792d1c8ad891fb3aeae9b80ab9e7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('rltsp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
